{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Collection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Academic articles are accessible through scholarly databases and collections of\n",
    "journals. Several databases and collections today offer access through an open \n",
    "Api. An Api is an application protocol interface that allows users to talk\n",
    "directly the database, skipping the user interface side of a journal.\n",
    "Interacting with the Api has two phases:\n",
    "\n",
    "\n",
    "- requesting;\n",
    "- receiving;\n",
    "\n",
    "\n",
    "The requesting phase includes composing a url with the requesting message.\n",
    "The head of the url includes the address of the Api and the tail the search \n",
    "argument, such as the word 'prisoner' to exists within the title. The address \n",
    "of the Api and the search arguments themselves differ from journal to journal, \n",
    "thus different journals can generate complete different requesting urls. \n",
    "\n",
    "The second phase of the receiving includes receiving a number of raw metadata of\n",
    "articles that satisfied the request. The answer is commonly received in an xml\n",
    "format but similarly the number of features and the syntax of the xml file \n",
    "differs from journal to journal.\n",
    "\n",
    "Data collection is a crucial proceeder. We wanted to include a large number of\n",
    "articles from various journal for the analysis to be objective. Moreover, we \n",
    "wanted the data to be collected within a short period of time. For these reasons\n",
    "an open source library was developed for the purpose of this work. The library\n",
    "is called Arcas and though the package it self will not be analysed here the \n",
    "source code can be found here, https://github.com/Nikoleta-v3/Arcas. \n",
    "\n",
    "Arcas serves as a translator between us and various Apis. More specifically it\n",
    "works in coordinate with five different journal. For Arcas to collect data a series\n",
    "of keywords had to be specified. Each keyword individually is checked weather\n",
    "it exists within the title or the abstract of an article. Only if this check is\n",
    "satisfied an article is collected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The open source python library [pandas](http://pandas.pydata.org/) will be used through out this article for the analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json('../data/data_nov_2017.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 10987 entries, 0 to 9999\n",
      "Data columns (total 14 columns):\n",
      "abstract           10987 non-null object\n",
      "author             10987 non-null object\n",
      "date               10987 non-null int64\n",
      "journal            10987 non-null object\n",
      "key                10987 non-null object\n",
      "key_word           10987 non-null object\n",
      "labels             10987 non-null object\n",
      "list_strategies    10987 non-null object\n",
      "pages              10987 non-null object\n",
      "provenance         10987 non-null object\n",
      "read               10987 non-null object\n",
      "score              10987 non-null object\n",
      "title              10987 non-null object\n",
      "unique_key         10987 non-null object\n",
      "dtypes: int64(1), object(13)\n",
      "memory usage: 1.3+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas info function shows us the information of the data set itself. \n",
    "\n",
    "We can see that the sata set contains the following columns:\n",
    "- Abstract. The abstract of the article.\n",
    "- Author. A single entity of an author from the list of authors of the respective article.\n",
    "- Date. Date of publication.\n",
    "- Journal. Journal of publication. \n",
    "- Key. A generated key containing an authors name and publication year (ex. Glynatsi2017).                \n",
    "- Key_word. A signle entity of a keyword assigned to the article by the given journal.\n",
    "- Labels. A single entity of labels assigned to the article manual by us.                 \n",
    "- Pages. Pages of publication.              \n",
    "- Provenance. Scholarly database for where the article was collected.                 \n",
    "- Score. Score given to article by the given journal.              \n",
    "- Title. Title of article.              \n",
    "- Unique key.  A unique key generated using the [hashlib python library](https://docs.python.org/2/library/hashlib.html). The hashable string is created by: [author name, title, year,abstract]\n",
    "\n",
    "\n",
    "The data set also contains the columns `list of strategies` and `read` but they are droped for this analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:literature]",
   "language": "python",
   "name": "conda-env-literature-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
